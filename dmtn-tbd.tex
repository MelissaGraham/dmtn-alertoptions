\documentclass[DM,lsstdraft,authoryear,toc]{lsstdoc}
% lsstdoc documentation: https://lsst-texmf.lsst.io/lsstdoc.html

% Package imports go here.
\usepackage{graphicx}
\usepackage{url}
\usepackage{latexsym}
\usepackage{color}
\usepackage{enumitem}

% Local commands go here.

% To add a short-form title:
% \title[Short title]{Title}
\title[Alerts Menu]{LSST Alerts: A Menu of Options}

% Optional subtitle
% \setDocSubtitle{A subtitle}

\author{%
M.~L.~Graham, and the Data Management System Science Team
}

\setDocRef{DMTN-MENU}
\date{\today}
% Optional: name of the document's curator
% \setDocCurator{The Curator of this Document}
\setDocUpstreamLocation{\url{https://github.com/lsst-dm/dmtn-xxx}}

\setDocAbstract{%
\textcolor{red}{\bf EXTREME DRAFT STATE. DO NOT CITE. DO NOT READ (YET!).}\\
A review and discussion of the variety of options for alert packets and their distribution, such as latency timescale, packet contents, pre-stream filtering, and so forth.
}

% Change history defined here.
% Order: oldest first.
% Fields: VERSION, DATE, DESCRIPTION, OWNER NAME.
% See LPM-51 for version number policy.
\setDocChangeRecord{%
  \addtohist{0}{2019-11-14}{Conception.}{Melissa Graham}
}

\begin{document}

% Create the title page.
% Table of contents is added automatically with the "toc" class option.
\maketitle

% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Introduction} \label{sec:intro}

The LSST Science Requirements Document \citedsp{LPM-17} specifies that information about the detections of transient, variable, and moving objects be released promptly as a data stream.

The purpose of this document is to consider the science motivation for, and impact of, the various options for alert packet contents and distribution timescales. 

The contents and delivery of alert packets play a major role in the scientific impact potential of LSST, in part because they are the only LSST data product that is both world public (exempt from a proprietary period) and publicly \emph{accessible}. While the contents of the Prompt products database (PPDB, from which alerts are generated) are also world public, \emph{access} to the PPDB is restricted to individuals with data rights \citedsp{LDO-013}.

It is a requirement\reqparam{numStreams}\dmreq{0391} that the DMS be capable of supporting the transmission of at least 5 full alert streams within 60 seconds of image readout. This is based in part on estimates of the alert stream data rate and the bandwidth allocated to alert distribution in the LSST data facility. The size and latency of alerts could affect the ultimate number of supported community alert brokers.

This draft contains content pertaining to the following open tickets in the DM-SST epic "Studies Around Alerts" (assignees):
\begin{itemize}
\item DM-19484, Estimate distribution of alert packet size based on scientific considerations (Bellm)
\item DM-15654, Define policy for handling fields with $>$10K alerts (Bellm)
\item DM-20296, Investigate the possibility of providing filtered streams (Graham)
\item DM-20298, Revise the contents of the alert packets (Graham)
\item DM-20299, Scientific use-cases requiring $<$5 minute access (Graham)
\item DM-20300, Investigate options for expanding access to the alert stream (Bellm)
\end{itemize}

% \lsrreq \ossreq \dmreq \reqparam 



\clearpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Alert Packet Contents} \label{sec:packets}

The section explores the science impacts of various options for alert packet contents, such as the $\sim$12 month history of {\tt DIASource} records, the image stamps, and the static-sky {\tt Object} catalog associations.

One of the positive scientific impacts of reducing the size of an alert packet is based on the assumption that the ability to transmit the stream to more community brokers would lead to more science being done with alerts. There is a potential secondary science impact, in that if brokers can spend less time developing software or spend less of their computational resources to, e.g., remove parts of the alert packet they do not need prior to processing, then they can spend more on developing and running algorithms for various alerts-related science goals. \S~\ref{ssec:packets_remove} and \ref{ssec:packets_compress} consider reducing the size of the alerts.


\subsection{Removing Histories and/or Stamps}\label{ssec:packets_remove}

The size of a fully-loaded individual alert packet is estimated to be $\lesssim$82~KB, based on simulations of the planned content of the alerts as described in Section 3.5 of \citeds{LSE-163}. The two largest components of the alert packet which could be considered "optional" are the history (the past $\sim$12 months of {\tt DIASource} records) and the stamps (at least 30$\times$30 pixels and contain flux (32 bit/pix), variance (32 bit/pix), and mask (16 bit/pix) extensions for both the template and difference image, plus a header of metadata \citedsp{LSE-163}). The history accounts for $\sim$27KB of the alert packet ($\sim$33\%) and the stamps contribute $\gtrsim$18~KB ($\sim$20\%). 

Brokers that save all alerts, build a database of alerts contents, or have an automated interface with the LSST Prompt products database or Alerts database, would not need the historical records to be included. Brokers which do not use the image stamps -- or would need them for only a subset of the alerts and could feasibly query a stamps database -- would not need them included in the alerts packets. Individual broker teams may indicate which information they require (or would like removed from the packets in their stream) during the broker proposal process \citedsp{LDM-682}, and \textcolor{red}{we should include that feedback in this document}.


If stamps are not sent in alerts, they need to be stored in a publicly accessible database

{\bf Remove histories and stamps from all alerts. --}

Pro: all transmitted streams have the same content and are identical (no need to keep on hand multiple versions of alert packets).

Con: negatively impact science with brokers which do not save or associate alerts but run in pure real-time (\textcolor{red}{check LOI to assess how many?})

{\bf Remove histories and stamps for some alert streams, at the request of brokers. --}

{\bf Never remove histories or stamps from any distributed alerts. --}

Pro: all transmitted streams have the same content and are identical (no need to keep on hand multiple versions of alert packets).

Pro: every alert packet contains all the public data and there is no need to provide, e.g., a \emph{publicly accessible} stamps database.


\subsection{Adding Associated {\tt Object} Record Elements}\label{ssec:packets_add}

The contents of the alert packet are defined in \citeds{LSE-163}. They will include {\tt nearbyObj} ({\tt unit64[6]}), the {\it "closest {\tt Objects} (3 stars and 3 galaxies) in Data Release database"}, {\tt nearbyObjDist} ({\tt float[6]}), the {\it "distances to {\tt nearbyObj}"} in arcseconds, and {\tt nearbyObjLnP} ({\tt float[6]}), the {\it "natural log of the probability that the observed {\tt DIAObject} is the same as the nearby {\tt Object}"}. For the latter, there is a footnote that says {\it "This quantity will be computed by marginalizing over the product of position and proper motion error ellipses of the {\tt Object} and {\tt DIAObject}, assuming an appropriate prior"}.

First, this definition of {\tt nearbyObjLnP} seems to only be appropriate for stars. For galaxies, the likelihood of a nearby galaxy being the true host is proportional to {\tt nearbyObjDist} divided by the effective radius of the host, or even better, \textcolor{red}{find the definition that uses semi-major and minor axies and the position angle etc.}. For this reason, the {\tt nearbyObj} included in the alerts should not simply be the three nearest galaxies -- it should be the \emph{three most likely host galaxies}. 

Second, the most useful piece of information about a transient's host galaxy is the redshift, because this significantly improves photometric classification algorithms \textcolor{red}{(could cite RAPID or Ashely's work and others)}. 

Including the three nearest stars remains appropriate because all stars have the same radial profile. For variable stars, \textcolor{red}{the most useful piece of information about its {\tt Object} is probably the mean apparent magnitude?}


\subsection{Compressing the Alert Packets}\label{ssec:packets_compress}

The application of gzip compression could further reduce the size of a full alert to $\sim$65~KB (80\%; JIRA ticket DM-16280). Naively, this seems like it would allow 1 more full stream to be transmitted to a broker, but the time and computational resources required to compress the alert packets has not been considered, \emph{and} this option would then force all brokers to decompress the alerts on arrival which might further delay processing for everyone. Science goals requiring low-latency alerts (\S~\ref{sec:latency}) could be negatively impacted.


\clearpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Alert Distribution Latency} \label{sec:latency}

It is a requirement that the DMS be capable of supporting the distribution of at least 98\%\reqparam{OTT1}\reqparam{OTR1}\lsrreq{0101}\lsrreq{0025}\ossreq{0127}\dmreq{0004} of alerts for each visit within 60 seconds of the end of image readout.

This section attempts to gather the science goals which might potentially require 1 minute alerts, and could not be satisfied with a longer latency (e.g., 5--10 minutes).

{\bf Target of Opportunity --} For rapid ToO observations with LSST, there might not be time for the pre-caching of slow database queries (e.g., loading slices of the PPDB catalogs) when the upcoming pointings are not known in advance, as they are for the regular survey observations. \textcolor{red}{$\leftarrow$ This statement was modified from something ECB mentioned on Slack, double check it's accurate}.


\subsection{Results of a TVS Survey About Alerts Timescales}\label{ssec:latency_tvs}

The Transients and Variable Stars (TVS) science collaboration surveyed the science needs of their members with respect to alert latency, and the results are shown in Table \ref{tab:tvs}\footnote{Results courtesy of TVS co-chair Rachel Street.}. The survey asked respondents to choose the maximum tolerable and ideal average delay between the alerts being produced by the LSST data reduction pipeline and the alert information becoming available through the broker service. This is not exactly the same as the alert distribution timescale {\tt OTT1}, but these responses will inform the need for $<$1 minute alert distribution.  Respondents were asked to provide a short summary of their science goals for alerts if they reported needed access within 15 minutes. The pool of respondents is probably not representative of the wider collaboration, and is likely biased towards individuals with science interests that do require faster access to alerts. 

Only 20\% (10\%) of respondents report that $<$10 minutes ($\leq$1 minute) is an ideal average delay, and whereas 70\% report that $>$30 minutes would be a sufficient average latency. The three science drivers associated with $<$5 minute alert access are the electromagnetic counterparts to gravitational wave events (EM-GW; kilonovae), young supernovae (early short-lived light curve features such as shock breakouts), and gamma-ray bursts (GRB). It might at first be confusing that EM-GW was provided as the science driver for such a wide range of alert access timescales, but this is discussed further in \S~\ref{ssec:latency_emgw}.

\begin{table}[h]%[htdp]
\caption{Table of results from a TVS survey which asked "how fast do you really need alerts?". The total number of respondents was 20. The science driver acronyms are: EM-GW (electromagnetic counterparts to gravitational wave events), YSNe (young supernovae), SBOs (???), GRBs (gamma-ray bursts). \label{tab:tvs}}
\begin{center}
\begin{tabular}{|l|cl|cl|}
\hline
             & Maximum & Science & Ideal       & Science \\
Latency & Tolerable  & Driver(s) &  Average & Driver(s) \\
\hline
1 min or less & 1 & EM-GW, GRB  & 2 & EM-GW, YSNe, GRB \\
1-5 min         & 0 &                          & 1 &                                   \\
5-10 min       & 1 & EM-GW, YSNe & 1 & SBOs \\
10-30 min     & 2 & SBOs               & 2 & EM-GW, GRBs \\
30-60 min     & 2 &                          & 7 & EM-GW  \\
1-6 hours     & 4 & EM-GW, GRBs & 1 &  \\
6-12 hours   & 2 &                          & 1 &  \\
12-24 hours & 3 & EM-GW            & 1 & EM-GW \\
1-3 days      & 1 &                           & 0 &  \\
>3 days       & 4 &                           & 4 &  \\
\hline
\end{tabular}
\end{center}
\label{default}
\end{table}%


\subsection{Solar System Objects}\label{ssec:latency_sso}

\textcolor{red}{MLG: in Lynne's talk on the SSSC needs for alerts brokers at the CBW in June 2019, slide 4 says that a needed broker capability was "API or other 'push' notification (e.g., trailed detections) [minutes may count]". Follow-up on the SS use case for alerts on very short timescales.}


\subsection{Young Supernovae}\label{ssec:latency_ysne}


\subsection{Fast Radio Bursts}\label{ssec:latency_frb}

\textcolor{red}{MLG: Can grab all the stuff you put into the CBW paper and put it here instead.}


\subsection{EM Counterparts to GW Events}\label{ssec:latency_emgw}
% From Slack conversation, Federica Bianco, Om Sharan Salafia, Eric Bellm

During LSST Operations, target-of-opportunity imaging follow-up sequences might be executed in the error ellipse of a gravitational wave (GW) detection to search for the electromagnetic (EM) optical counterpart. Such a search yielded a fast-evolving "kilonova" which decayed from 22 to 28th magnitude in the $g$-band in just 6 days \citep[faster in the bluer and slower in the redder filters][]{2017Sci...358.1559K}.

The timescale required for alerts access depends on the science goal regarding "kilonovae". The light curves last only a few days, and there is so far only the one GW170817, and so even if there was a day or two delay between discovery and the onset of optical follow-up, that's still going to lead to great science. However, the point of this section is to discuss the science motivation for very rapid alerts, 1 minute vs. 5 minutes vs. 10 minutes.



hi Fed, for what concerns ToO observations, I would say a very low latency would be optimal: I know that jet-powered (http://arxiv.org/abs/1705.10797) and/or proto-magnetar-powered (http://arxiv.org/abs/1508.07939) UV (and X-ray) transients from binary neutron star mergers are predicted to be detectable only up to ~1000 s following the merger. I cannot think of such a time-critical case for transients discovered during the main survey though...
arXiv.orgarXiv.org
The cocoon emission - an electromagnetic counterpart to...
Short Gamma-Ray Bursts (SGRBs) are believed to arise from compact binary mergers (either neutron star-neutron star or black hole-neutron star). If so their jets must penetrate outflows that are...
arXiv.orgarXiv.org
Electromagnetic emission from long-lived binary neutron star...
Recent observations indicate that in a large fraction of binary neutron star (BNS) mergers a long-lived neutron star (NS) may be formed rather than a black hole. Unambiguous electromagnetic (EM)...
3 replies



\subsection{Gamma-Ray Bursts}\label{ssec:latency_grb}

\subsection{Summary}\label{ssec:latency_summary}




\clearpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Pre-Filtered Alert Streams} \label{sec:prefilter}

Pre-filtered streams might mean the alerts can be distributed to more brokers than numStreams. What kind of pre-filters might suit the brokers?

 - magnitude or signal-to-noise ratio (affects completeness/purity)
 - region of sky (like one of the LOI for a particular region)
 - static-sky object association
 
 Image free streams of alert packets.
 Sources only associated with past alerts.

Provide estimates for how much the alert stream volume would be reduced.



\clearpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Graceful Degradation} \label{sec:graceful}

Along with the requirement of a 60 second alert distribution timescale (\S~\ref{sec:latency}, the DMS should support the distribution\reqparam{transN}\lsrreq{0101}\reqparam{nAlertVisitAvg}\ossreq{0193}\reqparam{nAlertVisitPeak}\dmreq{0393} of at least 10,000 alerts per standard visit on average during a given night, and at least 40,000 alerts per single standard visit. 

It is also a requirement\reqparam{sciVisitAlertDelay}\reqparam{sciVisitAlertFailure}\ossreq{0112}\dmreq{0392} that no more than 1\% of all standard visits fail to have at least 98\% of its alerts distributed within 60 seconds of image readout, and that no more than 0.1\% of all standard visits fail to distribute alerts.

These requirements apply to standard visits which should have produced $\leq$40,000 alerts. For example, a visit would be considered "delayed" and count towards that 1\% limit if $>$2\% of its alerts were distributed with a latency of $>$60 seconds. The requirement that no more than 0.1\% of all science visits fail to generate and/or distribute alerts is integrated over all stages of data handling, not just alert distribution, and includes failures at any stage of prompt processing.

It is furthermore specified that alert distribution "degrade gracefully" beyond that limit, meaning that visits resulting in an excess of alerts should not cause any DMS downtime \citedsp{LSE-30,LSE-61}.


In crowded fields there might be $>$40,000 difference-image sources.

For alerts that are not distributed within 60 seconds, how should they be handled? 

It is a requirement that all alerts be stored in an archival database and be available for retrieval\ossreq{0185}. The term "available for retrieval" applies to users with data rights and access to the LSST Science Platform. Like all other Prompt data products, the alerts archive will be updated within 24\reqparam{L1PublicT}\lsrreq{0104} hours \citedsp{LSE-29}.

\textcolor{red}{From the community post brokers FAQ $\rightarrow$}The retention period in the alert distribution system is still to be determined, but given the alert stream data rate of ~800 GB/night it is currently reasonable to expect a retention period of ~7 days. Brokers with data rights can retrieve old alert packets from the Alerts Database. However, note that the requirements on user access to the Alert Database are not yet fully developed, and may be limited in terms of how alert packets may be queried (e.g., alert ID), or by the bulk download capabilities (DMTN-102 1).



\clearpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{LSST Alert Filtering Service}\label{sec:lafs}

It is a requirement that the LSST alert filtering service be able to support\reqparam{numBrokerUsers}\dmreq{0343} at least 100 simultaneous users. The LAFS will be capable of returning 20\reqparam{numBrokerAlerts}\dmreq{0343} full-sized alerts per visit per user.

The LSST alerts filtering service is a mechanism by which users --- individuals with LSST data rights and access --- can receive alerts via pre-defined filters that have been optimized for established transient classifications such as supernovae and/or create and apply their own filters to the stream \citedsp{LPM-17,LSE-61}. 

Which options might be appropriate for implementation with the LAFS?
A few of these options might also be available to users of the LSST alert filtering service (\S~\ref{sec:LAFS}).


% Include all the relevant bib files.
% https://lsst-texmf.lsst.io/lsstdoc.html#bibliographies
\bibliography{local,lsst,lsst-dm,refs_ads,refs,books}

\end{document}
