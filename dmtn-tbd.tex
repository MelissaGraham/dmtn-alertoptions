\documentclass[DM,lsstdraft,authoryear,toc]{lsstdoc}
% lsstdoc documentation: https://lsst-texmf.lsst.io/lsstdoc.html

% Package imports go here.
\usepackage{graphicx}
\usepackage{url}
\usepackage{latexsym}
\usepackage{color}
\usepackage{enumitem}

% Local commands go here.

% To add a short-form title:
% \title[Short title]{Title}
\title[Alerts Menu]{LSST Alerts: A Menu of Options}

% Optional subtitle
% \setDocSubtitle{A subtitle}

\author{%
M.~L.~Graham, and the Data Management System Science Team
}

\setDocRef{DMTN-TBD}
\date{\today}
% Optional: name of the document's curator
% \setDocCurator{The Curator of this Document}
\setDocUpstreamLocation{\url{https://github.com/lsst-dm/dmtn-xxx}}

\setDocAbstract{%
\textcolor{red}{\bf EXTREME DRAFT STATE. DO NOT CITE. DO NOT READ (YET!).}\\
A review and discussion of the variety of options for alert packets and their distribution, such as latency timescale, packet contents, pre-stream filtering, and so forth.
}

% Change history defined here.
% Order: oldest first.
% Fields: VERSION, DATE, DESCRIPTION, OWNER NAME.
% See LPM-51 for version number policy.
\setDocChangeRecord{%
  \addtohist{0}{2019-11-14}{Conception.}{Melissa Graham}
}

\begin{document}

% Create the title page.
% Table of contents is added automatically with the "toc" class option.
\maketitle

% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Introduction} \label{sec:intro}

The LSST Science Requirements Document \citedsp{LPM-17} specifies that information about the detections of transient, variable, and moving objects be released promptly as a data stream.

The purpose of this document is to consider the science motivation for, and impact of, the various options for alert packet contents and distribution timescales. 

The contents and delivery of alert packets play a major role in the scientific impact potential of LSST, in part because they are the only LSST data product that is both world public (exempt from a proprietary period) and publicly \emph{accessible}. While the contents of the Prompt products database (PPDB, from which alerts are generated) are also world public, \emph{access} to the PPDB is restricted to individuals with data rights \citedsp{LDO-013}.

It is a requirement\reqparam{numStreams}\dmreq{0391} that the DMS be capable of supporting the transmission of at least 5 full alert streams within 60 seconds of image readout. This is based in part on estimates of the alert stream data rate and the bandwidth allocated to alert distribution in the LSST data facility. The size and latency of alerts could affect the ultimate number of supported community alert brokers.

This draft contains content pertaining to the following open tickets in the DM-SST epic "Studies Around Alerts" (assignees):
\begin{itemize}
\item DM-19484, Estimate distribution of alert packet size based on scientific considerations (Bellm)
\item DM-15654, Define policy for handling fields with $>$10K alerts (Bellm)
\item DM-20296, Investigate the possibility of providing filtered streams (Graham)
\item DM-20298, Revise the contents of the alert packets (Graham)
\item DM-20299, Scientific use-cases requiring $<$5 minute access (Graham)
\item DM-20300, Investigate options for expanding access to the alert stream (Bellm)
\end{itemize}

% \lsrreq \ossreq \dmreq \reqparam 



\clearpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Alert Packet Contents} \label{sec:packets}

The section explores the science impacts of various options for alert packet contents, such as the $\sim$12 month history of {\tt DIASource} records, the image stamps, and the static-sky {\tt Object} catalog associations.

One of the positive scientific impacts of reducing the size of an alert packet is based on the assumption that the ability to transmit the stream to more community brokers would lead to more science being done with alerts. There is a potential secondary science impact, in that if brokers can spend less time developing software or spend less of their computational resources to, e.g., remove parts of the alert packet they do not need prior to processing, then they can spend more on developing and running algorithms for various alerts-related science goals. \S~\ref{ssec:packets_remove} and \ref{ssec:packets_compress} consider reducing the size of the alerts.


\subsection{Removing Histories and/or Stamps}\label{ssec:packets_remove}

The size of a fully-loaded individual alert packet is estimated to be $\lesssim$82~KB, based on simulations of the planned content of the alerts as described in Section 3.5 of \citeds{LSE-163}. The two largest components of the alert packet which could be considered "optional" are the history (the past $\sim$12 months of {\tt DIASource} records) and the stamps (at least 30$\times$30 pixels and contain flux (32 bit/pix), variance (32 bit/pix), and mask (16 bit/pix) extensions for both the template and difference image, plus a header of metadata \citedsp{LSE-163}). The history accounts for $\sim$27KB of the alert packet ($\sim$33\%) and the stamps contribute $\gtrsim$18~KB ($\sim$20\%). 

Brokers that save all alerts, build a database of alerts contents, or have an automated interface with the LSST Prompt products database or Alerts database, would not need the historical records to be included. Brokers which do not use the image stamps -- or would need them for only a subset of the alerts and could feasibly query a stamps database -- would not need them included in the alerts packets. Individual broker teams may indicate which information they require (or would like removed from the packets in their stream) during the broker proposal process \citedsp{LDM-682}, and \textcolor{red}{we should include that feedback in this document}.


If stamps are not sent in alerts, they need to be stored in a publicly accessible database

{\bf Remove histories and stamps from all alerts. --}

Pro: all transmitted streams have the same content and are identical (no need to keep on hand multiple versions of alert packets).

Con: negatively impact science with brokers which do not save or associate alerts but run in pure real-time (\textcolor{red}{check LOI to assess how many?})

{\bf Remove histories and stamps for some alert streams, at the request of brokers. --}

{\bf Never remove histories or stamps from any distributed alerts. --}

Pro: all transmitted streams have the same content and are identical (no need to keep on hand multiple versions of alert packets).

Pro: every alert packet contains all the public data and there is no need to provide, e.g., a \emph{publicly accessible} stamps database.


\subsection{Adding Associated {\tt Object} Record Elements}\label{ssec:packets_add}

The contents of the alert packet are defined in \citeds{LSE-163}. They will include {\tt nearbyObj} ({\tt unit64[6]}), the {\it "closest {\tt Objects} (3 stars and 3 galaxies) in Data Release database"}, {\tt nearbyObjDist} ({\tt float[6]}), the {\it "distances to {\tt nearbyObj}"} in arcseconds, and {\tt nearbyObjLnP} ({\tt float[6]}), the {\it "natural log of the probability that the observed {\tt DIAObject} is the same as the nearby {\tt Object}"}. For the latter, there is a footnote that says {\it "This quantity will be computed by marginalizing over the product of position and proper motion error ellipses of the {\tt Object} and {\tt DIAObject}, assuming an appropriate prior"}.

First, this definition of {\tt nearbyObjLnP} seems to only be appropriate for stars. For galaxies, the likelihood of a nearby galaxy being the true host is proportional to {\tt nearbyObjDist} divided by the effective radius of the host, or even better, \textcolor{red}{find the definition that uses semi-major and minor axies and the position angle etc.}. For this reason, the {\tt nearbyObj} included in the alerts should not simply be the three nearest galaxies -- it should be the \emph{three most likely host galaxies}. 

Second, the most useful piece of information about a transient's host galaxy is the redshift, because this significantly improves photometric classification algorithms \textcolor{red}{(could cite RAPID or Ashely's work and others)}. 

Including the three nearest stars remains appropriate because all stars have the same radial profile. For variable stars, \textcolor{red}{the most useful piece of information about its {\tt Object} is probably the mean apparent magnitude?}


\subsection{Compressing the Alert Packets}\label{ssec:packets_compress}

The application of gzip compression could further reduce the size of a full alert to $\sim$65~KB (80\%; JIRA ticket DM-16280). Naively, this seems like it would allow 1 more full stream to be transmitted to a broker, but the time and computational resources required to compress the alert packets has not been considered, \emph{and} this option would then force all brokers to decompress the alerts on arrival which might further delay processing for everyone. Science goals requiring low-latency alerts (\S~\ref{sec:latency}) could be negatively impacted.


\clearpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Alert Distribution Latency} \label{sec:latency}

It is a requirement that the DMS be capable of supporting the distribution of at least 98\%\reqparam{OTT1}\reqparam{OTR1}\lsrreq{0101}\lsrreq{0025}\ossreq{0127}\dmreq{0004} of alerts for each visit within 60 seconds of the end of image readout.

If it is possible to relax this requirement to, e.g., 5 minutes -- \emph{without risk to the science goals} -- then it might be possible to support more community brokers and/or repurpose the human and computational resources that would otherwise be dedicated to delivering 1 minute alert distribution. This section attempts to gather the science goals which might potentially require 1 minute alert distribution and could not be satisfied with a longer latency.

{\bf Generally, science goals that require alerts on timescales shorter than $\sim$5 minutes have that need because they also require follow-up on timescales shorter than $\sim$15--30 minutes.} Most observing strategies for the WFD main survey do not revisit fields on timescales shorter than $\sim$15 minutes (strategies that do pair visits aim for closer to $\sim$22 minute gaps). Thus, any science goals driving the need for alerts on timescales shorter than $\sim$5 minutes \emph{must also be able to confidently identify their targets with single-epoch single-filter LSST photometry}, or be using additional information (such as host galaxy characteristics, or coincidence with another survey's data).

{\bf Target of Opportunity --} It is important to note that for rapid ToO observations with LSST (if they occur), there might not be time to pre-cache slow database queries (e.g., loading slices of the PPDB catalogs) when upcoming pointings are not known in advance, as would happen during regular survey observations. This might mean that a 1 minute alert distribution timescale for alerts from ToO imaging surveys cannot be guaranteed, and this should be kept in mind when reading through the science cases for short alert latencies in this section. \textcolor{red}{$\leftarrow$ This statement was modified from something ECB mentioned on Slack, double check it's accurate}.

\subsection{TVS Survey Results Regarding Alerts Timescales}\label{ssec:latency_tvs}

The Transients and Variable Stars (TVS) science collaboration surveyed the science needs of their members with respect to alert latency, and the results are shown in Table \ref{tab:tvs}\footnote{Results courtesy of TVS co-chair Rachel Street.}. The survey asked respondents to choose the maximum tolerable and ideal average delay between the alerts being produced by the LSST data reduction pipeline and the alert information becoming available through the broker service. This is not exactly the same as the alert distribution timescale {\tt OTT1}, but these responses will inform the need for $<$1 minute alert distribution.  Respondents were asked to provide a short summary of their science goals for alerts if they reported needed access within 15 minutes. Note that the pool of respondents is probably not representative of the wider collaboration, and is likely biased towards individuals with science interests that do require faster access to alerts. 

Only 20\% (10\%) of respondents report that $<$10 minutes ($\leq$1 minute) is an ideal average delay, and whereas 70\% report that $>$30 minutes would be a sufficient average latency. The three science drivers associated with $<$5 minute alert access are the electromagnetic counterparts to gravitational wave events (EM-GW; kilonovae), young supernovae (early short-lived light curve features such as shock breakouts), and gamma-ray bursts (GRB). It is at first confusing that EM-GW was provided as the science driver for such a wide range of alert access timescales, but this is discussed further in \S~\ref{ssec:latency_emgw}, along with several other science cases that rely on rapid access to LSST alerts.

\begin{table}[h]%[htdp]
\caption{Table of results from a TVS survey which asked "how fast do you really need alerts?". The total number of respondents was 20. The science driver acronyms are: EM-GW (electromagnetic counterparts to gravitational wave events), YSNe (young supernovae, including e.g., shock breakouts), GRBs (gamma-ray bursts). \label{tab:tvs}}
\begin{center}
\begin{tabular}{|l|cl|cl|}
\hline
             & Maximum & Science & Ideal       & Science \\
Latency & Tolerable  & Driver(s) &  Average & Driver(s) \\
\hline
1 min or less & 1 & EM-GW, GRB  & 2 & EM-GW, YSNe, GRB \\
1-5 min         & 0 &                          & 1 &                                   \\
5-10 min       & 1 & EM-GW, YSNe & 1 & YSNe \\
10-30 min     & 2 & YSNe               & 2 & EM-GW, GRBs \\
30-60 min     & 2 &                          & 7 & EM-GW  \\
1-6 hours     & 4 & EM-GW, GRBs & 1 &  \\
6-12 hours   & 2 &                          & 1 &  \\
12-24 hours & 3 & EM-GW            & 1 & EM-GW \\
1-3 days      & 1 &                           & 0 &  \\
>3 days       & 4 &                           & 4 &  \\
\hline
\end{tabular}
\end{center}
\label{default}
\end{table}%


\subsection{EM Counterparts to GW Events}\label{ssec:latency_emgw}
% From Slack conversation, Federica Bianco, Om Sharan Salafia, Eric Bellm

During LSST Operations, target-of-opportunity imaging follow-up sequences might be executed in the error ellipse of a gravitational wave (GW) detection to search for the electromagnetic (EM) optical counterpart. Such a search yielded a fast-evolving "kilonova" which decayed from 22 to 28th magnitude in the $g$-band in just 6 days \citep[faster in the bluer and slower in the redder filters][]{2017Sci...358.1559K}. Although the kilonova light curves last only a few days, since there is so far only one event, GW170817, a day or two delay between the GW event and the optical detection still yields very scientifically valuable data -- for now. During LSST Operations there will already exist a sizable collection of longer-latency follow-up, and it is likely that science will be moving in the direction of pushing to ever earlier detections. However, since KNe produce days-long optical afterglows, a 5 minute LSST alerts would likely suffice.

There are two theoretical predictions for prompt optical emission that would require very rapid access to alerts. One of them is a potential faint, $<$1 hour, UV/optical transient that occurs at the time of jet-break out for a short gamma-ray burst associated with a binary neutron star merger (\S~\ref{ssec:latency_grb}). Another that predicts emission of a similar color, luminosity, and timescale is the spin-down energy of a long-lived ($10^2$--$10^4$ s) neutron star formed from a binary neutron star merger before its eventual collapse to a black hole \citep{2016ApJ...819...15S}. As described in \S~\ref{ssec:latency_grb}, very few events could be detected by serendipitous coincidence by the LSST WFD main survey, and targeted follow-up of well-localized GW events with more appropriate facilities (such as space-based UV/optical imagers) is much more likely to yield detections of this very short lived emission.

There are two additional issues related to ToO for EMGW events which might make 1 minute alerts necessary or impossible. First, as described above, for a ToO imaging survey with LSST there might not be time to pre-load catalogs for the targeted fields. The second is that, at least for run O3, the GW event detection system itself issues preliminary alerts within 1--10 minutes, and these preliminary alerts are often retracted and do not always have the sky localization. Even now, many imaging follow-up surveys wait for the initial alert (or retraction) to be sent after a round of human vetting of the GW event signal, and this can take several hours. With such latencies, the 1 {\it vs.} 5 minute LSST alert timescales becomes inconsequential. 



\subsection{Gamma-Ray Bursts}\label{ssec:latency_grb}

For short gamma-ray bursts (sGRBs) which are thought to be the mergers of two neutron stars, or a neutron star and a black hole, as the jet propagates through the ejecta material a hot cocoon is formed. When cocoon and jet break out, along with sGRB can can be observed as a blue transient with an absolute peak brightness of -12 to -15 magnitudes that lasts for $10^3$--$10^4$ seconds (e.g., \citealt{2018MNRAS.473..576G}). For an LSST detection limit of $r\sim24$ mag, a detection limit of $r\lesssim-12$ ($r\lesssim-15$) mag corresponds to distances of $\lesssim160$ ($\lesssim630$) Mpc, or redshifts $z\lesssim0.035$ ($z\lesssim0.14$). Observing the diversity of cocoon emission will require multi-band follow-up within $10^3$ seconds, or $15$ minutes, and in this particular case a 5 minute alert distribution latency is too long to include the shorter events (or the fainter events for which only the peak would be visible).

% z=0.035 is V=0.014 Gpc3
% z=0.14 is V=0.836 Gpc3
% (0.836/0.014) * 4/yr = 240/yr

The rate of short GRBs in the local volume ($<$200 Mpc) is estimated to be quite low, $<$4 $\rm yr^{-1}$ \citep{2019arXiv190800100M}. Scaling this up to the co-moving volume within 630 Mpc is $\sim$240 $\rm yr^{-1}$, all-sky. In the baseline main survey, about a sixth of the sky can be observed in a given night, which is $\lesssim$0.1 event in the WFD main survey area per night. With $\sim$1000 visits per night, and $\sim$10 visits every 5 minutes, there's a $10^{-3}$ chance that the location of a sGRB will be serendipitously observed within 5 minutes of the event on a given night. So this could happen once every 3 years, or $\sim$3 times over the 10-year LSST main survey.

For this particular science case, LSST seems to be the wrong tool for the job. As described by \citet{2018MNRAS.473..576G}, a rapid search at the location of sGRBs with a UV satellite such as ULTRASAT would be ideal.

%Triggering criteria might be:
%new {\it u}- or {\it g}-band source with recent limits associated with a $<$200 Mpc galaxy (how many expected per night?)
%and then very high priority if it's serendipidously associated with a GRB detection in the last 5 minutes


\subsection{Young Supernovae}\label{ssec:latency_ysne}


\subsection{Fast Radio Bursts}\label{ssec:latency_frb}

\textcolor{red}{MLG: Can grab all the stuff you put into the CBW paper and put it here instead.}


\subsection{Solar System Objects}\label{ssec:latency_sso}

\textcolor{red}{MLG: in Lynne's talk on the SSSC needs for alerts brokers at the CBW in June 2019, slide 4 says that a needed broker capability was "API or other 'push' notification (e.g., trailed detections) [minutes may count]". Follow-up on the SS use case for alerts on very short timescales.}


\subsection{Summary}\label{ssec:latency_summary}




\clearpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Pre-Filtered Alert Streams} \label{sec:prefilter}

Pre-filtered streams might mean the alerts can be distributed to more brokers than numStreams. What kind of pre-filters might suit the brokers?

 - magnitude or signal-to-noise ratio (affects completeness/purity)
 - region of sky (like one of the LOI for a particular region)
 - static-sky object association
 
 Image free streams of alert packets.
 Sources only associated with past alerts.

Provide estimates for how much the alert stream volume would be reduced.



\clearpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Graceful Degradation} \label{sec:graceful}

Along with the requirement of a 60 second alert distribution timescale (\S~\ref{sec:latency}, the DMS should support the distribution\reqparam{transN}\lsrreq{0101}\reqparam{nAlertVisitAvg}\ossreq{0193}\reqparam{nAlertVisitPeak}\dmreq{0393} of at least 10,000 alerts per standard visit on average during a given night, and at least 40,000 alerts per single standard visit. 

It is also a requirement\reqparam{sciVisitAlertDelay}\reqparam{sciVisitAlertFailure}\ossreq{0112}\dmreq{0392} that no more than 1\% of all standard visits fail to have at least 98\% of its alerts distributed within 60 seconds of image readout, and that no more than 0.1\% of all standard visits fail to distribute alerts.

These requirements apply to standard visits which should have produced $\leq$40,000 alerts. For example, a visit would be considered "delayed" and count towards that 1\% limit if $>$2\% of its alerts were distributed with a latency of $>$60 seconds. The requirement that no more than 0.1\% of all science visits fail to generate and/or distribute alerts is integrated over all stages of data handling, not just alert distribution, and includes failures at any stage of prompt processing.

It is furthermore specified that alert distribution "degrade gracefully" beyond that limit, meaning that visits resulting in an excess of alerts should not cause any DMS downtime \citedsp{LSE-30,LSE-61}.


In crowded fields there might be $>$40,000 difference-image sources.

For alerts that are not distributed within 60 seconds, how should they be handled? 

It is a requirement that all alerts be stored in an archival database and be available for retrieval\ossreq{0185}. The term "available for retrieval" applies to users with data rights and access to the LSST Science Platform. Like all other Prompt data products, the alerts archive will be updated within 24\reqparam{L1PublicT}\lsrreq{0104} hours \citedsp{LSE-29}.

\textcolor{red}{From the community post brokers FAQ $\rightarrow$}The retention period in the alert distribution system is still to be determined, but given the alert stream data rate of ~800 GB/night it is currently reasonable to expect a retention period of ~7 days. Brokers with data rights can retrieve old alert packets from the Alerts Database. However, note that the requirements on user access to the Alert Database are not yet fully developed, and may be limited in terms of how alert packets may be queried (e.g., alert ID), or by the bulk download capabilities (DMTN-102 1).



\clearpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{LSST Alert Filtering Service}\label{sec:lafs}

It is a requirement that the LSST alert filtering service be able to support\reqparam{numBrokerUsers}\dmreq{0343} at least 100 simultaneous users. The LAFS will be capable of returning 20\reqparam{numBrokerAlerts}\dmreq{0343} full-sized alerts per visit per user.

The LSST alerts filtering service is a mechanism by which users --- individuals with LSST data rights and access --- can receive alerts via pre-defined filters that have been optimized for established transient classifications such as supernovae and/or create and apply their own filters to the stream \citedsp{LPM-17,LSE-61}. 

Which options might be appropriate for implementation with the LAFS?
A few of these options might also be available to users of the LSST alert filtering service (\S~\ref{sec:LAFS}).


% Include all the relevant bib files.
% https://lsst-texmf.lsst.io/lsstdoc.html#bibliographies
\bibliography{local,lsst,lsst-dm,refs_ads,refs,books}

\end{document}
