\documentclass[DM,lsstdraft,authoryear,toc]{lsstdoc}
% lsstdoc documentation: https://lsst-texmf.lsst.io/lsstdoc.html

% Package imports go here.
\usepackage{graphicx}
\usepackage{url}
\usepackage{latexsym}
\usepackage{color}
\usepackage{enumitem}

% Local commands go here.

% To add a short-form title:
% \title[Short title]{Title}
\title[Alerts Contents]{LSST Alerts: A Scientific Perspective on Packet Contents and Pre-Filtering}

% Optional subtitle
% \setDocSubtitle{A subtitle}

\author{%
M.~L.~Graham and the Data Management System Science Team
}

\setDocRef{DMTN-TBD}
\date{\today}
% Optional: name of the document's curator
% \setDocCurator{The Curator of this Document}
\setDocUpstreamLocation{\url{https://github.com/lsst-dm/dmtn-xxx}}

\setDocAbstract{%
\textcolor{red}{\bf EXTREME DRAFT STATE. DO NOT CITE OR READ.}\\
\textcolor{red}{The DM-SST will return to this document once the broker full proposals have been received, as they will contain more information on these topics.}\\
A review and discussion of the science motivation for, and impacts of, the variety of options for alert packets contents (e.g., histories, stamps) and pre-filtered streams (based on, e.g., apparent magnitude, {\tt Object} assocation). A brief discussion about the science impacts for the various ways of implementing a ``graceful degradation" of $>$40000 alerts per visit. }

% Change history defined here.
% Order: oldest first.
% Fields: VERSION, DATE, DESCRIPTION, OWNER NAME.
% See LPM-51 for version number policy.
\setDocChangeRecord{%
  \addtohist{0}{2019-11-14}{Inception.}{Melissa Graham}
  \addtohist{0.1}{2020-01-09}{First draft.}{Melissa Graham}
}

\begin{document}

% Cite requirements using these macros.
% \lsrreq \ossreq \dmreq \reqparam 

% Create the title page.
% Table of contents is added automatically with the "toc" class option.
\maketitle

% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Introduction} \label{sec:intro}

% The LSST Science Requirements Document \citedsp{LPM-17} specifies that information about the detections of transient, variable, and moving objects be released promptly as a data stream.

The alert packets will play a major role in the scientific impact of LSST, in part because they are the only LSST data product that is both world public (exempt from any proprietary period) and publicly accessible, as they are distributed to community brokers and not solely available via the LSST Science Platform (LSP).
In comparison, although the contents of the Prompt products database (PPDB) from which alerts are generated are also world public, access to the PPDB is restricted to individuals with data rights \citedsp{LDO-013} who have authenticated accounts in the LSP.

This document considers options for the alert packet contents and potential ``pre-filters" of the alert stream based on those contents. 
The alert packets, as described in \citeds{LSE-163}, were designed to include all the relevant LSST data about a source that a broker might need to assess, classify, and prioritize the alert for follow-up observations \emph{within minutes} (i.e., on order the timescale of the 60 second alert distribution latency).

It is a requirement\reqparam{numStreams}\dmreq{0391} that the DMS be capable of supporting the transmission of at least 5 full alert streams within 60 seconds of image readout.
This is based in part on estimates of the alert stream data rate and the bandwidth allocated to alert distribution in the LSST data facility.
Reducing the packet size by narrowing down the contents included, and/or reducing the number of alerts distributed by applying a pre-filter, could enable alerts to be delivered to more brokers, and thereby increase the amount of alerts-related science done by the community.

\S~\ref{sec:packets} discusses how removing stamps and histories from alerts could be scientifically beneficial for some brokers, as long as stamps are made publicly available with similar latency.
\S~\ref{sec:prefilter} lists types of pre-filtered streams that could improve brokers' scientific productivity and estimates the resulting bandwidth reductions, and \S~\ref{sec:graceful} argues that when alerts are delayed, the scientifically optimal response would be to flag and distribute them as soon as possible (and not, e.g., send them directly to an archive).

\clearpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Alert Packet Contents} \label{sec:packets}

In this section the scientific impacts of various options to reduce the size of alert packets (in order to, e.g., enable wider alert distribution, facilitate broker processing) are considered, as are potential additions to the alert packet contents which would improve the user's ability to classify and prioritize alert sources for follow-up.
The main conclusions of the following discussion are:
\begin{itemize}
\item {\bf Removing Histories (\S~\ref{sssec:packets_remove_hist}) ---} Removing the {\tt DIASource} histories from the alert packets that are transmitted to brokers that request this modification could be scientifically beneficial, but a list of all {\tt DIASource} identifiers associated with the {\tt DIAObject} at the time of alert generation must be added to those packets. 
\item {\bf Removing Stamps (\S~\ref{sssec:packets_remove_stamps}) ---} Removing the image stamps from all alert packets could be scientifically beneficial, but stamps should still be made during alert production and made publicly retrievable with a latency similar to that of alert distribution.
\item {\bf Distributing Multiple Packet Formats (\S~\ref{sssec:packets_remove_procon}) ---} From a science perspective, distributing non-identical alert packets would have no negative impact provided that full-sized packets do not become more prone to delays.
\item {\bf Compressing Packets (\S~\ref{ssec:packets_compress}) ---} From a science perspective, compressing the alert packets has little scientific impact unless it imposes a large additional latency on alert distribution, which could be detrimental to alerts-related science.
\end{itemize}

\subsection{Removing Histories and/or Stamps}\label{ssec:packets_remove}

The size of a fully-loaded individual alert packet is estimated to be $\lesssim$82~KB, based on simulations of the planned content of the alerts as described in Section 3.5 of \citeds{LSE-163} (see also \citeds{DMTN-102}).
The two largest components of the alert packet which could be considered ``optional'' are the history and the postage stamps.
The history is the past $\sim$12 months of {\tt DIASource} records, previously released as alerts.
The postage stamps are, at minimum, 30$\times$30 pixels and contain flux, variance, and mask extensions for both the template and difference image, plus a header of metadata \citedsp{LSE-163}.
The history accounts for $\sim$27KB of the alert packet ($\sim$33\%) and the stamps contribute $\gtrsim$18~KB ($\sim$20\%). 

Brokers that save all alerts, build their own a database of alerts contents, or have an automated interface with the LSST Prompt products database or Alerts database might not need the historical records to be included in the alert packets.
Brokers which do not use the image stamps -- or would need them for only a subset of the alerts and could feasibly query a stamps database -- might not need them included in the alerts packets.
Individual broker teams may indicate which information they require (or would like removed from the packets in their stream) during the broker proposal process \citedsp{LDM-612,LDM-682,LDM-723}.
During the first stages of the proposal process, and at the LSST Community Brokers Workshop\footnote{\url{ls.st/cbw}} in June 2019, there was some indication that at least a few brokers were interested in alerts without historical records and/or postage historical records.

\subsubsection{{\tt DIASource} Record History}\label{sssec:packets_remove_hist}

Including the {\tt DIASource} record history in every alert allows for the \emph{instant assessment} --- without the need to cross-match or query catalogs --- of changes in the objects's location, size, shape, or brightness, provides context for the latest detection (i.e., anomalous or typical), and enables a robust assessment of the likely physical nature of the object (e.g., light curve fits indicating supernova type become more reliable with more observations). 

To remove the {\tt DIASource} record history from an alert would slightly inhibit the scientific assessment of transient/variable objects for brokers that build their own database of alert contents, due to the time required to cross-match with the database.
Removing the {\tt DIASource} record history would completely inhibit this kind of analysis for brokers that do not have such storage or processing capabilities.

There is also the issue that the association of {\tt DIASources} into {\tt DIAObjects} may change over time, for some objects.
For example, rare cases such as multiply-imaged strongly-lensed supernovae, or two unassociated transients/variables that are superimposed along the line of sight, might be blended/separated in poor/good seeing.
In such cases, the set of all associated {\tt DIASources} might be improved between one alert and the next. 

{\bf Summary --} The {\tt DIASource} record histories should not be removed from all alert packets, but could be optionally removed at the request of a broker.
However, if the record histories are removed, a list of all {\tt DIASource} identifiers (the {\tt diaSourceId}, as in Section 3.3.1 of \citeds{LSE-163}) which are currently associated with the {\tt DIAObject} to which the alert-spawning {\tt DIASource} is associated should be provided (note that this list is \emph{not} currently part of the {\tt DIAObject} record).

\subsubsection{Forced Photometry History}\label{sssec:packets_remove_fp}

When forced photometry ({\tt DIAForcedSource} record history) is included in an alert packet, it is ``historical" in the sense that it is based on past images and not the image which spawned the alert.
However, it is not always redundant information that was previously released in an alert, like the {\tt DIASource} record history.

There are two main cases where forced photometry is performed, as described in \citeds{LSE-163}.
(1) For all new {\tt DIAObjects}, forced ``pre-covery'' photometry is done in the past 30 days of difference images within 24 hours, stored in the {\tt DIAForcedSource} catalog, and included in all future alert packets associated with that {\tt DIAObject}.
(2) For all {\tt DIAObjects} that are not detected\footnote{The detection threshold is a signal-to-noise ratio $\geq$ 5.} in a given difference image, but had a detection in the past $\sim$12 months, forced photometry is done on that difference image.
The result is stored in the {\tt DIAForcedSource} catalog, and included in all future alert packets associated with that {\tt DIAObject}.
The forced photometry is scientifically valuable because, for example, pre-covery forced photometry provides context for the first detection of a transient/variable, and low-SNR detections can help with photometric classification and prioritization for follow-up observations. 

If a given {\tt DIAObject} is never again detected in a difference image, then the {\tt DIAForceSource} records are never included in an alert packet, but are available to individuals or brokers with access to the PPDB via the LSST Science Platform.
If a given {\tt DIAObject} is repeatedly detected in new difference images, then the same {\tt DIAForcedSource} records will be redundantly included in all future alerts (after the first one containing the pre-covery or non-detection forced photometry).
For the ``historical" {\tt DIAForcedSource} records, alert content redundancy could be avoided by only including previously undistributed {\tt DIAForcedSource} data in an alert packet.
To do this, the Prompt pipeline would have to either compare with the contents of the most recent alert and remove redundant data from the new alert, or flag the {\tt DIAForcedSource} data as ``released" and only add ``unreleased" forced photometry to a alert packet.
Both of these options would add processing times to the alert generation pipeline, which is undesirable.

{\bf Summary --} If the decision is made to remove the historical {\tt DIASource} records from alert packets, the {\tt DIAForcedSource} records of forced photometry should always be added to all alerts.
This will cause some redundancy in alert contents, but if not included there would be no public access to this scientifically valuable information.

\subsubsection{Postage Stamps}\label{sssec:packets_remove_stamps}

\textcolor{red}{MLG notes from DESC: not all alerts need them so it could be, e.g., for new DIASources only, non-stellar DIASources, etc. with the rest going to a server that does not have the 1 minute latency requirements.}

Including the postage stamps in the alert packet allows for the instant assessment of the {\tt DIASource} in the difference and template images, which has a variety of scientific applications.
For example, although real/bogus classification of the difference-image sources will be done prior to alert generation, some brokers may still wish to run additional algorithms on the images -- especially in the case of first detections.
Brokers might also employ algorithms to classify transients and variables based on the images instead of the photometry (e.g., \citealt{2019PASP..131j8006C}).
From the postage stamp images, scientifically useful information can be derived about the trails left by moving objects, or from the 2-dimensional luminosity distribution of spatially evolving objects such as comets, which might not be entirely captured by the {\tt DIASource} elements (see Table 1 in \citeds{LSE-163}).
The images also provide context for the {\tt DIASource}, such as host-galaxy morphology or field crowdedness, that can assist with follow-up observations.

If postage stamps were not created during alert production, the only option would be for users to wait until the images are made available (within 24 hours) in the LSP, which would significantly inhibit alerts-based science goals.
However, postage stamps are unlikely to be needed for most {\tt DIASources}, the majority of which --- 95\%, according to the breakdown in \citeds{DMTN-102} --- will be stars or asteroids: point sources for which context is not a significant part of their immediate evaluation.
An efficient compromise might be for the Prompt pipeline to create the postage stamps during alert generation, and then store them in a publicly accessible database (i.e., outside the LSP) where they can be obtained (via {\tt diaSourceId}) with a latency similar to the alert distribution timescale by anyone, from anywhere, at anytime. 

The expected maximum download rate from this stamp database is estimated by assuming that all 5 community brokers download $\sim$500 stamp sets per visit: $\sim$2500 stamp sets every $\sim$35 seconds.
At 18~KB per stamp set, that's a data rate of 10.5 Mbps (for comparison, that's $\sim$5\% of one full alert stream).

{\bf Summary --} The postage stamps could be removed from all alert packets, but they should still be created during Prompt processing and stored in a publicly accessible database where they can be obtained with a latency similar to the alert distribution timescale.

\textcolor{red}{{\bf Could Postage Stamps Be Smaller? --}}
\citeds{LSE-163} describes the size of the postage stamp to be at least $6\arcsec \times 6\arcsec$ ($30\times30$ pixels), or large enough to encompass the entire footprint of the {\tt DIASource} (e.g., if trailed, extended). 
That is large enough to contain the angular diameter (30 kpc) of a Milky Way-like galaxy at a redshift of $z\approx0.5$, which will be a fairly typical supernova host galaxy in the LSST data set.
Since context is a science driver for producing stamps, it would not be desirable for them to be much smaller than $6\arcsec \times 6\arcsec$.


\subsubsection{Pros and Cons of Multiple Alert Formats}\label{sssec:packets_remove_procon}

The histories and/or stamps could be removed from all alert packets, or only at the request of a broker.
In the latter case, LSST might end up distributing four types of alert packet formats to its five brokers: (i) with histories and stamps, (ii) with histories but without stamps, (iii) without histories but with stamps, and (iv) without histories or stamps. 

From a science perspective, the benefits to allowing brokers to customize their alert packet is that it potentially enables unique science to be done by brokers (e.g., very rapid custom stamp-analysis algorithms), and could enable LSST to support $>$5 brokers which might lead to more alerts-related science in general.

One drawback might arise during times of heavy load, such as many visits with $>$40,000 alerts (\S~\ref{sec:graceful}), \emph{if}, and only if, full-sized packet streams are more likely to be delayed.
Whether this becomes a possibility will depend on the technical aspects of how the multiple types of alerts are generated and transmitted, and also on the final decisions about delayed distribution (\S~\ref{sec:graceful}).
This may well never come to pass, but if it did, it could be unfair to brokers requiring full-size packets.
While some brokers are being designed for a wide variety of science goals, others are more specifically tailored.
If it is the specifically-tailored broker that requires full-sized alerts, then experiencing delayed transmission more frequently than other brokers could put some science goals at a disadvantage. 
Furthermore, the fact that not all alert packets are identical might cause some additional bookkeeping considerations for downstream brokers who ingest from multiple community brokers, but that should not be detrimental to their science goals.
The technical considerations of how many different alert packet formats it is feasible to create and transmit within the required latency time is beyond the scope of this document, in which we focus on science impacts.

{\bf Summary --} Offering multiple alert formats to brokers is scientifically beneficial provided that full-sized alerts are not predisposed to delay.

\subsection{Compressing the Alert Packets}\label{ssec:packets_compress}

The application of gzip compression could further reduce the size of a full alert to $\sim$65~KB (80\%; JIRA ticket DM-16280).
Naively, this seems like it would allow 1 more full stream to be transmitted to a broker, and thereby enable more science.
However, the time and computational resources required to compress the alert packets needs to be considered.
For example, gzip compression at 50 MB/s to compress $\sim$10000 alerts would take $\sim$10000 $\times$0.08 MB per alert $/$50 MB/s, or $\sim$16 seconds.
This is significant, considering the alert distribution latency requirement\reqparam{OTT1}\lsrreq{0101}\ossreq{0127}\dmreq{0004} is 60 seconds. 
Furthermore, compressing the alert packets forces brokers to then decompress the alerts on arrival, which would incur further delay.
Science goals requiring very low-latency alerts distribution might be negatively impacted by compression.

{\bf Summary --} Since packet compression could induce an additional latency, perhaps it should only be done if, e.g., an algorithm could provide a compression rate of $\lesssim$10 MB/s (requiring only a few seconds to compress a visit's worth of alerts), or if the alert distribution latency requirement is relaxed from 1 minute (not currently planned).
Otherwise, compression would have no impact on alerts-related science goals and so this should be primarily a technically-driven decision.



\clearpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Pre-Filtered Alert Streams} \label{sec:prefilter}

This section explores the scientific motivation and impact of offering brokers pre-filtered alert streams. 
Pre-filtering could reduce the overall bandwidth of alert distribution and potentially allow streams to be transmitted to more brokers, thereby enabling more alerts-related science.
Providing pre-filtered streams could also lessen the load and resources used by the brokers, enabling more alerts-related science by allowing brokers to spend a smaller fraction of their budget computational resources.

Depending on the science goals of a given broker and/or their users, a broker might find it useful to only receive alerts for {\tt DIASources} which:
\begin{itemize}
\item are likely to have a certain physical origin, e.g., stellar variable, moving objects
\item could potentially be observed by the follow-up resources its users have access to
\item have at least one prior detection by LSST (because, e.g., their algorithms all require photometric confirmation or a change in brightness)
\item originate in images obtained as part of a special program such as the deep drilling fields or target-of-opportunity imaging surveys
\item were not obtained during poor weather conditions (e.g., an image quality or sky background violating some limit)
\end{itemize}

For the above science drivers, the types of pre-filters that are likely to be scientifically useful -- some of which have been suggested by brokers already -- include:
\begin{itemize}
\item {\bf Apparent Magnitude:} only {\tt DIASources} brighter than a specified apparent magnitude (for each of the LSST filters {\it ugrizy}) are transmitted. 
\item {\bf Region of Sky:} only {\tt DIASources} in a given sky area (or areas; defined by, e.g., limits in right ascension or declination), are transmitted. 
\item \texttt{\bf DIAObject} {\bf History:} only {\tt DIASources} associated with {\tt DIAObjects} that have at least $N$ previous detections are transmitted, where $N$ can be $\geq1$. 
\item \texttt{\bf SSObject} {\bf Association:} only {\tt DIASources} that are associated with a {\tt SSObject} are transmitted. (Potentially including new, unassociated {\tt DIASources}, because they might also be moving objects).
\item \texttt{\bf Object} {\bf Association:} only {\tt DIASources} associated with {\tt DIAObjects} that are, in turn, associated with a data release {\tt Object} that meets some specification are transmitted (e.g., associated with a stellar point source).
\item {\bf Observation Metadata:} only alerts from images obtained with a given set of metadata, e.g., a special observing program or meeting sky condition thresholds, are transmitted.
\end{itemize}

All of these potential science-driven pre-filters are based on the information contained in the alert itself, and do not impose any additional processing on the Prompt pipeline.
They all also have the potential to considerably reduce the number of transmitted alerts.
Due to the exponential relationship between the number of variable stars and their variability amplitude, and also that of volume and distance modulus, an apparent magnitude limit $\sim1$ mag brighter than the nominal $5{\sigma}$ {\tt DIASource} detection limit could reduce the alert stream data rate by $\gtrsim50$\%.
Limiting to alerts that are associated with past detections or certain types of objects could similarly reduce the alert stream data rate.
These types of pre-filers would reduce the number of alerts per visit for all visits -- the average bandwidth -- which might enable alert distribution to extend to more brokers and thus enable more alerts-related LSST science.
Pre-filters based on their sky location or observational metadata would probably either deliver all or none of the alerts for a given visit, causing fluctuations in the bandwidth but not necessarily in a way that would allow for additional streams to be transmitted.


% % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{LSST Alert Filtering Service}\label{ssec:prefilter_lafs}

As described in \citeds{LSE-163} the LSST will provide an alert filtering service with limited capacity, by which individuals with LSST data rights and access may receive alerts via pre-defined filters and/or create and apply their own filters to the stream \citedsp{LPM-17,LSE-61}.
It is a requirement that the LSST alert filtering service be able to support\reqparam{numBrokerUsers}\dmreq{0343} at least 100 simultaneous users, and capable of returning 20\reqparam{numBrokerAlerts}\dmreq{0343} full-sized alerts per visit per user.
User-generated filters may be comprised of, e.g., a series of {\tt if} statements applied to the alert packet elements.
There are no requirements on the latency of filter execution, which may depend on the complexity of the filter and available resources. 

From a science perspective, it would be beneficial to offer any and all of the pre-filtered streams listed above as options for user-generated filters.
Individual users running small follow-up programs are more likely to have access to smaller-aperture telescopes and thus desire an initial apparent magnitude cut.
It would save on compute resources to avoid a situation in which, e.g., 50 user-generated brokers all start with an {\tt if} statement to filter the stream to, e.g., $m_r < 20$ mag. 

% One type of simple filtering that individual users are more likely to want than brokers is ``watchlist" capability -- lists of individual objects (stars or galaxies) and offset radii that alerts are desired within. 





\clearpage
% % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Graceful Degradation} \label{sec:graceful}

The LSST specifications for the DMS require that it support the distribution\reqparam{transN}\lsrreq{0101}\reqparam{nAlertVisitAvg}\ossreq{0193}\reqparam{nAlertVisitPeak}\dmreq{0393} of at least 40,000 alerts per single standard visit, and that for visits producing $\leq$40,000 alerts \reqparam{sciVisitAlertDelay}\reqparam{sciVisitAlertFailure}\ossreq{0112}\dmreq{0392} no more than 1\% of them fail to have at least 98\% of its alerts distributed within 60 seconds of image readout.
It is furthermore specified that alert distribution "degrade gracefully" beyond that limit, meaning that visits resulting in an excess of 40,000 of alerts should not cause any DMS downtime \citedsp{LSE-30,LSE-61}.

This leaves the open question of what, from a science perspective, is the optimal way of dealing with delayed alerts that also meets the DMS specification of a ``graceful degradation"?
We leave the aspects of technical implementation of a ``graceful degradation", such as distributing delayed alerts and alert archive storage access, for elsewhere and here just consider the science implications for a delayed timescale.

{\bf Next-opportunity distribution via the alert stream.} There are plenty of science goals that do not absolutely require alert distribution in 1 minute, and so distributing delayed alerts via the stream would still enable plenty of science.
The brokers might prefer to have delayed alerts clearly flagged to properly process them (e.g., some filtering and processing done by brokers might only be appropriate for alerts delivered within a given latency).

{\bf Next-morning distribution via the alert stream.} This refers to an option to collect all delayed alerts during the night and then releasing them (perhaps on a new ``topic") in the morning after survey operations have ended for the night.
From a science perspective this is not as useful as next-opportunity distribution, but if it is preferred for technical reasons it would enable more science than the option below.

{\bf Do not distribute delayed alerts; send directly to archive.} There is no scientific merit in not distributing delayed alerts, and two further drawbacks: the alert archive update timescale is 24 hours\reqparam{L1PublicT}, significantly slower than next-morning distribution, and the alert archive might only be accessible by brokers with data rights since it is part of the LSST Data Facility.

% MLG: commented out technical implementation aspects.
%The retention period of alert packets in the alert distribution system is still to be determined, but given the alert stream data rate of ~800 GB/night it is currently reasonable to expect a retention period of ~7 days. 
% It is a requirement that all alerts be stored in an archival database and be available for retrieval\ossreq{0185}.
%The term ``available for retrieval" applies to users with data rights and access to the LSST Science Platform.
%Like all other Prompt data products, the alerts archive will be updated within 24\reqparam{L1PublicT}\lsrreq{0104} hours \citedsp{LSE-29}.
% However, note that the requirements on user access to the alerts archive are not yet fully developed, and may be limited in terms of how alert packets may be queried (e.g., alert ID), or by the bulk download capabilities.


\clearpage
% Include all the relevant bib files.
% https://lsst-texmf.lsst.io/lsstdoc.html#bibliographies
\bibliography{local,lsst,lsst-dm,refs_ads,refs,books}

\end{document}
